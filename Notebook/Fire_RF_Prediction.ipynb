{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc84e861",
   "metadata": {},
   "source": [
    "Step 1: Resample Prediction Bands from 10m to 20m (for Training)\n",
    "To train the model, you need both predictors (X) and target (y) at the same resolution. Resample your 10m prediction bands to 20m to match the observed dNBR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0294479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# from rasterio.enums import Resampling\n",
    "# import numpy as np\n",
    "\n",
    "# def resample_to_coarse(input_path, output_path, target_resolution=20):\n",
    "#     \"\"\"\n",
    "#     Resample 10m prediction bands to 20m resolution\n",
    "#     \"\"\"\n",
    "#     with rasterio.open(input_path) as src:\n",
    "#         # Calculate scale factor (downsampling from 10m to 20m)\n",
    "#         scale_factor = target_resolution / src.res[0]  # 20/10 = 0.5\n",
    "        \n",
    "#         # Read and resample data\n",
    "#         data = src.read(\n",
    "#             out_shape=(\n",
    "#                 src.count,\n",
    "#                 int(src.height * scale_factor),\n",
    "#                 int(src.width * scale_factor)\n",
    "#             ),\n",
    "#             resampling=Resampling.average  # Use average for downsampling\n",
    "#         )\n",
    "        \n",
    "#         # Update transform\n",
    "#         transform = src.transform * src.transform.scale(\n",
    "#             (src.width / data.shape[-1]),\n",
    "#             (src.height / data.shape[-2])\n",
    "#         )\n",
    "        \n",
    "#         # Write resampled raster\n",
    "#         profile = src.profile.copy()\n",
    "#         profile.update({\n",
    "#             'height': data.shape[1],\n",
    "#             'width': data.shape[2],\n",
    "#             'transform': transform\n",
    "#         })\n",
    "        \n",
    "#         with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "#             dst.write(data)\n",
    "    \n",
    "#     print(f\"Resampled to {target_resolution}m: {output_path}\")\n",
    "\n",
    "# # Resample prediction bands from 10m to 20m for training\n",
    "# resample_to_coarse(\n",
    "#     '/Users/ceedindia/Desktop/Fire/Data/GSE_Bandipur_Prediction_Band.tif', \n",
    "#     '/Users/ceedindia/Desktop/Fire/Data/GSE_Bandipur_prediction_bands_20m.tif', \n",
    "#     target_resolution=20\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3474f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "\n",
    "# input_path = '/Users/ceedindia/Desktop/Fire/Data/Trial/GSE_Dirang_Prediction_Band.tif'\n",
    "# output_path = '/Users/ceedindia/Desktop/Fire/Data/Trial/GSE_Dirang_Prediction_Band_after64.tif'\n",
    "\n",
    "# with rasterio.open(input_path) as src:\n",
    "#     # Select bands after the first 64\n",
    "#     bands_to_keep = list(range(65, src.count + 1))\n",
    "#     profile = src.profile\n",
    "#     profile.update(count=len(bands_to_keep))\n",
    "\n",
    "#     with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "#         for new_idx, old_idx in enumerate(bands_to_keep, start=1):\n",
    "#             dst.write(src.read(old_idx), new_idx)\n",
    "#             if src.descriptions:\n",
    "#                 dst.set_band_description(new_idx, src.descriptions[old_idx - 1])\n",
    "\n",
    "# print(\"Successfully created a new file without the first 64 bands:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51809baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "# def resample_to_coarse(input_path, output_path, target_resolution=20):\n",
    "#     \"\"\"\n",
    "#     Resample 10m prediction bands to 20m resolution safely (works in meters).\n",
    "#     If CRS is geographic (EPSG:4326), reproject to a projected CRS first.\n",
    "#     \"\"\"\n",
    "#     with rasterio.open(input_path) as src:\n",
    "#         # If CRS is in degrees, switch to UTM (based on the raster center)\n",
    "#         if src.crs.is_geographic:\n",
    "#             lon, lat = (src.bounds.left + src.bounds.right)/2, (src.bounds.top + src.bounds.bottom)/2\n",
    "#             utm_zone = int((lon + 180) / 6) + 1\n",
    "#             new_crs = f\"EPSG:{32600 + utm_zone if lat >= 0 else 32700 + utm_zone}\"\n",
    "#             print(f\"Reprojecting from {src.crs} → {new_crs} for meter-based resampling...\")\n",
    "#         else:\n",
    "#             new_crs = src.crs\n",
    "\n",
    "#         transform, width, height = calculate_default_transform(\n",
    "#             src.crs, new_crs, src.width, src.height, *src.bounds, resolution=target_resolution\n",
    "#         )\n",
    "\n",
    "#         profile = src.profile.copy()\n",
    "#         profile.update({\n",
    "#             \"crs\": new_crs,\n",
    "#             \"transform\": transform,\n",
    "#             \"width\": width,\n",
    "#             \"height\": height\n",
    "#         })\n",
    "\n",
    "#         with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "#             for i in range(1, src.count + 1):\n",
    "#                 reproject(\n",
    "#                     source=rasterio.band(src, i),\n",
    "#                     destination=rasterio.band(dst, i),\n",
    "#                     src_transform=src.transform,\n",
    "#                     src_crs=src.crs,\n",
    "#                     dst_transform=transform,\n",
    "#                     dst_crs=new_crs,\n",
    "#                     resampling=Resampling.average\n",
    "#                 )\n",
    "\n",
    "#     print(f\"✅ Resampled raster saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f857de01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample_to_coarse(\n",
    "#     '/Users/ceedindia/Desktop/Fire/Data/Trial/GSE_Dirang_Prediction_Band_after64.tif',\n",
    "#     '/Users/ceedindia/Desktop/Fire/Data/Trial/GSE_Dirang_Prediction_Band_after64.tif_resampled20.tif',\n",
    "#     target_resolution=20\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adddf03d",
   "metadata": {},
   "source": [
    "Step 2: Convert 20m Rasters to DataFrame (Training Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "417ff118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (7798, 69)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import numpy as np\n",
    "\n",
    "def raster_to_dataframe_20m(prediction_20m_path, observed_20m_path):\n",
    "    \"\"\"\n",
    "    Convert 20m resolution rasters to dataframe for training.\n",
    "    Automatically aligns observed raster to prediction raster grid.\n",
    "    \"\"\"\n",
    "    # Read prediction bands\n",
    "    with rasterio.open(prediction_20m_path) as pred_src:\n",
    "        pred_data = pred_src.read()  # (n_bands, height, width)\n",
    "        n_bands = pred_src.count\n",
    "        height, width = pred_src.height, pred_src.width\n",
    "        transform = pred_src.transform\n",
    "        crs = pred_src.crs\n",
    "        \n",
    "        # Coordinates\n",
    "        rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
    "        xs, ys = rasterio.transform.xy(transform, rows.flatten(), cols.flatten())\n",
    "\n",
    "        # Flatten prediction data\n",
    "        pred_data_flat = pred_data.reshape(n_bands, -1).T\n",
    "        df = pd.DataFrame(pred_data_flat, columns=[f'band_{i+1}' for i in range(n_bands)])\n",
    "        df['longitude'] = xs\n",
    "        df['latitude'] = ys\n",
    "\n",
    "    # Read observed raster and align to prediction grid\n",
    "    with rasterio.open(observed_20m_path) as obs_src:\n",
    "        obs_data = np.empty((height, width), dtype=np.float32)\n",
    "        reproject(\n",
    "            source=rasterio.band(obs_src, 1),\n",
    "            destination=obs_data,\n",
    "            src_transform=obs_src.transform,\n",
    "            src_crs=obs_src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        df['observed_dnbr'] = obs_data.flatten()\n",
    "\n",
    "    # Clean dataframe\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train_20m = raster_to_dataframe_20m(\n",
    "    '/Users/ceedindia/Desktop/Fire/Data/Trial/GSE_Dirang_Prediction_Band_after64.tif_resampled20.tif',\n",
    "    '/Users/ceedindia/Desktop/Fire/Data/Trial/Observed_dNBR_20m_Dirang.tif'\n",
    ")\n",
    "print(f\"Training data shape: {df_train_20m.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abf384",
   "metadata": {},
   "source": [
    "Step 3: Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb61180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features (20m): (7798, 66)\n",
      "Training Target (20m): (7798,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "feature_cols = [col for col in df_train_20m.columns if col.startswith('band_')]\n",
    "X_20m = df_train_20m[feature_cols]\n",
    "y_20m = df_train_20m['observed_dnbr']\n",
    "\n",
    "print(f\"Training Features (20m): {X_20m.shape}\")\n",
    "print(f\"Training Target (20m): {y_20m.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb43cc",
   "metadata": {},
   "source": [
    "# VIF (Variance Inflation Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0fabbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 'band_65' with VIF = 5304.21\n",
      "Dropping 'band_59' with VIF = 1295.44\n",
      "Dropping 'band_43' with VIF = 975.25\n",
      "Dropping 'band_60' with VIF = 871.14\n",
      "Dropping 'band_48' with VIF = 811.04\n",
      "Dropping 'band_35' with VIF = 792.61\n",
      "Dropping 'band_4' with VIF = 752.41\n",
      "Dropping 'band_13' with VIF = 723.06\n",
      "Dropping 'band_3' with VIF = 608.75\n",
      "Dropping 'band_54' with VIF = 492.61\n",
      "Dropping 'band_53' with VIF = 446.78\n",
      "Dropping 'band_17' with VIF = 390.43\n",
      "Dropping 'band_8' with VIF = 386.62\n",
      "Dropping 'band_22' with VIF = 361.84\n",
      "Dropping 'band_16' with VIF = 354.88\n",
      "Dropping 'band_2' with VIF = 335.14\n",
      "Dropping 'band_10' with VIF = 304.48\n",
      "Dropping 'band_46' with VIF = 291.04\n",
      "Dropping 'band_20' with VIF = 268.79\n",
      "Dropping 'band_58' with VIF = 263.09\n",
      "Dropping 'band_24' with VIF = 210.72\n",
      "Dropping 'band_42' with VIF = 173.54\n",
      "Dropping 'band_36' with VIF = 166.38\n",
      "Dropping 'band_64' with VIF = 162.42\n",
      "Dropping 'band_12' with VIF = 154.78\n",
      "Dropping 'band_29' with VIF = 154.16\n",
      "Dropping 'band_32' with VIF = 148.30\n",
      "Dropping 'band_19' with VIF = 140.67\n",
      "Dropping 'band_56' with VIF = 117.37\n",
      "Dropping 'band_57' with VIF = 108.53\n",
      "Dropping 'band_62' with VIF = 89.38\n",
      "Dropping 'band_15' with VIF = 79.44\n",
      "Dropping 'band_7' with VIF = 69.32\n",
      "Dropping 'band_47' with VIF = 66.86\n",
      "Dropping 'band_21' with VIF = 61.61\n",
      "Dropping 'band_55' with VIF = 58.63\n",
      "Dropping 'band_25' with VIF = 55.20\n",
      "Dropping 'band_18' with VIF = 48.40\n",
      "Dropping 'band_14' with VIF = 37.56\n",
      "Dropping 'band_11' with VIF = 35.75\n",
      "Dropping 'band_50' with VIF = 29.13\n",
      "Dropping 'band_23' with VIF = 28.88\n",
      "Dropping 'band_51' with VIF = 18.17\n",
      "Dropping 'band_5' with VIF = 17.57\n",
      "Dropping 'band_34' with VIF = 15.59\n",
      "Dropping 'band_45' with VIF = 12.67\n",
      "\n",
      "Final set of features after VIF filtering:\n",
      "['band_1', 'band_6', 'band_9', 'band_26', 'band_27', 'band_28', 'band_30', 'band_31', 'band_33', 'band_37', 'band_38', 'band_39', 'band_40', 'band_41', 'band_44', 'band_49', 'band_52', 'band_61', 'band_63', 'band_66']\n",
      "\n",
      "Final VIF values:\n",
      "    Feature       VIF\n",
      "0    band_1  5.176357\n",
      "1    band_6  2.986276\n",
      "2    band_9  4.093008\n",
      "3   band_26  7.964786\n",
      "4   band_27  3.239770\n",
      "5   band_28  9.347915\n",
      "6   band_30  7.604349\n",
      "7   band_31  8.674722\n",
      "8   band_33  7.940472\n",
      "9   band_37  2.235219\n",
      "10  band_38  9.018951\n",
      "11  band_39  3.557131\n",
      "12  band_40  6.751444\n",
      "13  band_41  9.469857\n",
      "14  band_44  9.159094\n",
      "15  band_49  4.135096\n",
      "16  band_52  6.633901\n",
      "17  band_61  5.309988\n",
      "18  band_63  7.261343\n",
      "19  band_66  5.406980\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Function to calculate VIF and remove features above threshold\n",
    "def calculate_vif(X, threshold=10):\n",
    "    \"\"\"\n",
    "    Iteratively removes features with VIF greater than the given threshold.\n",
    "    \"\"\"\n",
    "    variables = X.columns.tolist()\n",
    "    dropped = True\n",
    "\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"Feature\"] = variables\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X[variables].values, i) for i in range(X[variables].shape[1])]\n",
    "\n",
    "        max_vif = vif[\"VIF\"].max()\n",
    "        if max_vif > threshold:\n",
    "            max_vif_feature = vif.loc[vif[\"VIF\"] == max_vif, \"Feature\"].values[0]\n",
    "            print(f\"Dropping '{max_vif_feature}' with VIF = {max_vif:.2f}\")\n",
    "            variables.remove(max_vif_feature)\n",
    "            dropped = True\n",
    "\n",
    "    print(\"\\nFinal set of features after VIF filtering:\")\n",
    "    print(variables)\n",
    "    return X[variables], vif\n",
    "\n",
    "# Run VIF calculation on training features (20m)\n",
    "X_20m_vif, vif_20m = calculate_vif(X_20m, threshold=10)\n",
    "\n",
    "# View final VIF table\n",
    "print(\"\\nFinal VIF values:\")\n",
    "print(vif_20m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d683b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_20m = X_20m_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0382de",
   "metadata": {},
   "source": [
    "Step 4: Train-Test Split (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a5013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_20m shape: (7798, 20)\n",
      "y_20m shape: (7798,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_20m shape:\", X_20m.shape)\n",
    "print(\"y_20m shape:\", y_20m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "253c9fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5458\n",
      "Testing samples: 2340\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data 70:30\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_20m, y_20m, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5278d2",
   "metadata": {},
   "source": [
    "Step 5: Random Forest with Hyperparameter Tuning (10-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4fd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest hyperparameter tuning (10-fold CV)...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=500; total time=   4.4s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=500; total time=   4.3s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=500; total time=   4.6s\n",
      "[CV] END .max_depth=10, max_features=sqrt, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=10, max_features=sqrt, n_estimators=1000; total time=  10.0s\n",
      "[CV] END .max_depth=10, max_features=sqrt, n_estimators=1000; total time=  10.0s\n",
      "[CV] END ..max_depth=10, max_features=None, n_estimators=500; total time=  18.7s\n",
      "[CV] END .max_depth=10, max_features=sqrt, n_estimators=2000; total time=  19.1s\n",
      "[CV] END .max_depth=10, max_features=sqrt, n_estimators=2000; total time=  19.2s\n",
      "[CV] END .max_depth=10, max_features=sqrt, n_estimators=2000; total time=  19.6s\n",
      "[CV] END ..max_depth=10, max_features=None, n_estimators=500; total time=  19.1s\n",
      "[CV] END ..max_depth=10, max_features=None, n_estimators=500; total time=  19.1s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=500; total time=   6.4s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=500; total time=   6.5s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=500; total time=   6.0s\n",
      "[CV] END .max_depth=20, max_features=sqrt, n_estimators=1000; total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .max_depth=20, max_features=sqrt, n_estimators=1000; total time=  13.6s\n",
      "[CV] END .max_depth=20, max_features=sqrt, n_estimators=1000; total time=  13.8s\n",
      "[CV] END .max_depth=10, max_features=None, n_estimators=1000; total time=  37.5s\n",
      "[CV] END .max_depth=10, max_features=None, n_estimators=1000; total time=  34.9s\n",
      "[CV] END .max_depth=10, max_features=None, n_estimators=1000; total time=  35.4s\n",
      "[CV] END .max_depth=20, max_features=sqrt, n_estimators=2000; total time=  23.8s\n",
      "[CV] END .max_depth=20, max_features=sqrt, n_estimators=2000; total time=  24.2s\n",
      "[CV] END ..max_depth=20, max_features=None, n_estimators=500; total time=  22.6s\n",
      "[CV] END ..max_depth=20, max_features=None, n_estimators=500; total time=  22.9s\n",
      "[CV] END .max_depth=20, max_features=sqrt, n_estimators=2000; total time=  23.8s\n",
      "[CV] END ..max_depth=20, max_features=None, n_estimators=500; total time=  24.3s\n",
      "[CV] END .max_depth=10, max_features=None, n_estimators=2000; total time= 1.2min\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=500; total time=   7.4s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=500; total time=   6.5s\n",
      "[CV] END .max_depth=10, max_features=None, n_estimators=2000; total time= 1.2min\n",
      "[CV] END .max_depth=10, max_features=None, n_estimators=2000; total time= 1.2min\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=500; total time=   6.6s\n",
      "[CV] END .max_depth=30, max_features=sqrt, n_estimators=1000; total time=  13.6s\n",
      "[CV] END .max_depth=30, max_features=sqrt, n_estimators=1000; total time=  13.3s\n",
      "[CV] END .max_depth=30, max_features=sqrt, n_estimators=1000; total time=  13.2s\n",
      "[CV] END .max_depth=20, max_features=None, n_estimators=1000; total time=  49.3s\n",
      "[CV] END .max_depth=20, max_features=None, n_estimators=1000; total time=  47.2s\n",
      "[CV] END .max_depth=20, max_features=None, n_estimators=1000; total time=  47.6s\n",
      "[CV] END .max_depth=30, max_features=sqrt, n_estimators=2000; total time=  23.8s\n",
      "[CV] END .max_depth=30, max_features=sqrt, n_estimators=2000; total time=  22.5s\n",
      "[CV] END .max_depth=30, max_features=sqrt, n_estimators=2000; total time=  23.7s\n",
      "[CV] END ..max_depth=30, max_features=None, n_estimators=500; total time=  22.1s\n",
      "[CV] END ..max_depth=30, max_features=None, n_estimators=500; total time=  22.1s\n",
      "[CV] END ..max_depth=30, max_features=None, n_estimators=500; total time=  22.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=500; total time=   6.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=500; total time=   6.9s\n",
      "[CV] END .max_depth=20, max_features=None, n_estimators=2000; total time= 1.6min\n",
      "[CV] END .max_depth=20, max_features=None, n_estimators=2000; total time= 1.6min\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=1000; total time=  14.5s\n",
      "[CV] END .max_depth=20, max_features=None, n_estimators=2000; total time= 1.6min\n",
      "[CV] END .max_depth=30, max_features=None, n_estimators=1000; total time=  52.5s\n",
      "[CV] END .max_depth=30, max_features=None, n_estimators=1000; total time=  52.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=1000; total time=  14.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=1000; total time=  15.4s\n",
      "[CV] END .max_depth=30, max_features=None, n_estimators=1000; total time=  53.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=2000; total time=  29.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=2000; total time=  30.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=2000; total time=  30.2s\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=500; total time=  27.5s\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=500; total time=  27.8s\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=500; total time=  25.0s\n",
      "[CV] END .max_depth=30, max_features=None, n_estimators=2000; total time= 1.7min\n",
      "[CV] END .max_depth=30, max_features=None, n_estimators=2000; total time= 1.7min\n",
      "[CV] END .max_depth=30, max_features=None, n_estimators=2000; total time= 1.7min\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=1000; total time=  47.3s\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=1000; total time=  39.4s\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=1000; total time=  39.4s\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=2000; total time=  54.8s\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=2000; total time=  49.5s\n",
      "[CV] END max_depth=None, max_features=None, n_estimators=2000; total time=  49.0s\n",
      "\n",
      "Best RF parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [500, 1000, 2000], # 500, 1000, 2000 # 500,\n",
    "    'max_depth': [10, 20, 30, None], ## 10 30 50  10, \n",
    "#    'min_samples_split': [2, 5, 10],\n",
    "#    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', None] ## sqrt , 'log2', \n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# GridSearchCV with 10-fold CV\n",
    "print(\"Random Forest hyperparameter tuning (10-fold CV)...\")\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "print(f\"\\nBest RF parameters: {rf_grid_search.best_params_}\")\n",
    "best_rf_model = rf_grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49ff1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import time\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import numpy as np\n",
    "\n",
    "# # Define parameter grid\n",
    "# rf_param_grid = {\n",
    "#     'n_estimators': [500, 1000],\n",
    "#     'max_depth': [20, 30, None],\n",
    "#     'max_features': ['sqrt', None]\n",
    "# }\n",
    "\n",
    "# # Generate all parameter combinations\n",
    "# param_combinations = list(itertools.product(\n",
    "#     rf_param_grid['n_estimators'],\n",
    "#     rf_param_grid['max_depth'],\n",
    "#     rf_param_grid['max_features']\n",
    "# ))\n",
    "\n",
    "# print(f\"Total combinations to test: {len(param_combinations)}\")\n",
    "\n",
    "# results = []\n",
    "\n",
    "# # Start progress bar\n",
    "# for params in tqdm(param_combinations, desc=\"Grid Search Progress\", unit=\"combination\"):\n",
    "#     n_estimators, max_depth, max_features = params\n",
    "    \n",
    "#     model = RandomForestRegressor(\n",
    "#         n_estimators=n_estimators,\n",
    "#         max_depth=max_depth,\n",
    "#         max_features=max_features,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "    \n",
    "#     # 3-fold cross-validation\n",
    "#     scores = cross_val_score(model, X_train, y_train, cv=3,\n",
    "#                              scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "#     results.append({\n",
    "#         'n_estimators': n_estimators,\n",
    "#         'max_depth': max_depth,\n",
    "#         'max_features': max_features,\n",
    "#         'mean_score': np.mean(scores)\n",
    "#     })\n",
    "\n",
    "# # Find best combination\n",
    "# best = max(results, key=lambda x: x['mean_score'])\n",
    "# print(\"\\n✅ Best Parameters:\")\n",
    "# print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618011c6",
   "metadata": {},
   "source": [
    "Step 6: 10-Fold Cross-Validation on Best RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac3f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 10-fold CV RMSE: 0.0731\n"
     ]
    }
   ],
   "source": [
    "# 5-fold CV on best model\n",
    "rf_cv_scores_5fold = cross_val_score(\n",
    "    best_rf_model, X_train, y_train, \n",
    "    cv=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_cv_rmse = np.sqrt(-rf_cv_scores_5fold.mean())\n",
    "print(f\"RF 10-fold CV RMSE: {rf_cv_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b3242",
   "metadata": {},
   "source": [
    "Step 7: Test Set Evaluation for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "542dff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict and evaluate\n",
    "# y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "# rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# print(f\"\\nRF Test Performance:\")\n",
    "# print(f\"RMSE: {rf_rmse:.4f}\")\n",
    "# print(f\"R²: {rf_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce63a16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF Test Performance:\n",
      "RMSE: 0.0698\n",
      "MAE: 0.0468\n",
      "MAPE: 47.72%\n",
      "R²: 0.8443\n",
      "\n",
      "Accuracy Matrix:\n",
      "                    ±5%       ±10%       ±15%       ±20%\n",
      "Accuracy (%)  12.564103  25.470085  36.923077  46.923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "# Avoid division by zero\n",
    "non_zero_mask = y_test != 0\n",
    "rf_mape = np.mean(np.abs((y_test[non_zero_mask] - y_pred_rf[non_zero_mask]) / y_test[non_zero_mask])) * 100\n",
    "\n",
    "# Compute accuracy for multiple tolerances\n",
    "tolerances = [0.05, 0.10, 0.15, 0.20]  # ±5%, ±10%, ±15%, ±20%\n",
    "accuracy_data = {}\n",
    "\n",
    "for tol in tolerances:\n",
    "    within_tol = np.abs((y_pred_rf - y_test) / y_test) <= tol\n",
    "    accuracy = np.mean(within_tol) * 100\n",
    "    accuracy_data[f'±{int(tol*100)}%'] = [accuracy]\n",
    "\n",
    "accuracy_matrix = pd.DataFrame(accuracy_data, index=['Accuracy (%)'])\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"\\nRF Test Performance:\")\n",
    "print(f\"RMSE: {rf_rmse:.4f}\")\n",
    "print(f\"MAE: {rf_mae:.4f}\")\n",
    "print(f\"MAPE: {rf_mape:.2f}%\")\n",
    "print(f\"R²: {rf_r2:.4f}\")\n",
    "print(\"\\nAccuracy Matrix:\")\n",
    "print(accuracy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7797c000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Random Forest Prediction Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27738744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 10-fold CV RMSE (training set estimate): 0.0731\n",
      "\n",
      "RF Test Performance on unseen test set:\n",
      "RMSE: 0.0698\n",
      "MAE: 0.0468\n",
      "MAPE: 47.72%\n",
      "R²: 0.8443\n",
      "\n",
      "Accuracy Matrix:\n",
      "                    ±5%       ±10%       ±15%       ±20%\n",
      "Accuracy (%)  12.564103  25.470085  36.923077  46.923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 10-fold cross-validation on training data using best_rf_model\n",
    "rf_cv_scores_10fold = cross_val_score(\n",
    "    best_rf_model, X_train, y_train, \n",
    "    cv=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_cv_rmse = np.sqrt(-rf_cv_scores_10fold.mean())\n",
    "print(f\"RF 10-fold CV RMSE (training set estimate): {rf_cv_rmse:.4f}\")\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data and evaluate\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE) - avoid division by zero\n",
    "non_zero_mask = y_test != 0\n",
    "rf_mape = np.mean(np.abs((y_test[non_zero_mask] - y_pred_rf[non_zero_mask]) / y_test[non_zero_mask])) * 100\n",
    "\n",
    "# Accuracy at different tolerance levels\n",
    "tolerances = [0.05, 0.10, 0.15, 0.20]  # ±5%, ±10%, ±15%, ±20%\n",
    "accuracy_data = {}\n",
    "\n",
    "for tol in tolerances:\n",
    "    within_tol = np.abs((y_pred_rf - y_test) / y_test) <= tol\n",
    "    accuracy = np.mean(within_tol) * 100\n",
    "    accuracy_data[f'±{int(tol*100)}%'] = [accuracy]\n",
    "\n",
    "accuracy_matrix = pd.DataFrame(accuracy_data, index=['Accuracy (%)'])\n",
    "\n",
    "# Print final test set performance metrics\n",
    "print(f\"\\nRF Test Performance on unseen test set:\")\n",
    "print(f\"RMSE: {rf_rmse:.4f}\")\n",
    "print(f\"MAE: {rf_mae:.4f}\")\n",
    "print(f\"MAPE: {rf_mape:.2f}%\")\n",
    "print(f\"R²: {rf_r2:.4f}\")\n",
    "print(\"\\nAccuracy Matrix:\")\n",
    "print(accuracy_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091bf75c",
   "metadata": {},
   "source": [
    "# Prediction to Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "476d1d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands: 130  | Shape: (130, 179, 246)\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# Path to your GSE raster stack (10 m resolution)\n",
    "gse_stack_path = '/Users/ceedindia/Desktop/Fire/Data/Trial/GSE_Dirang_Prediction_Band.tif'\n",
    "\n",
    "# Open the raster stack\n",
    "with rasterio.open(gse_stack_path) as src:\n",
    "    gse_stack = src.read()  # shape: (bands, rows, cols)\n",
    "    profile = src.profile\n",
    "    print(\"Bands:\", src.count, \" | Shape:\", gse_stack.shape)\n",
    "\n",
    "# Reshape raster data for prediction\n",
    "n_bands, n_rows, n_cols = gse_stack.shape\n",
    "gse_2d = gse_stack.reshape(n_bands, -1).T  # shape: (pixels, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9d125df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature order preserved: ['band_1', 'band_6', 'band_9', 'band_26', 'band_27', 'band_28', 'band_30', 'band_31', 'band_33', 'band_37', 'band_38', 'band_39', 'band_40', 'band_41', 'band_44', 'band_49', 'band_52', 'band_61', 'band_63', 'band_66']\n"
     ]
    }
   ],
   "source": [
    "# Assuming you trained with feature columns 'band_1', 'band_2', ..., 'band_n'\n",
    "feature_names = [col for col in X_train.columns]\n",
    "print(\"Feature order preserved:\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b46b504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands in full GSE stack: 130\n",
      "Shape before selection: (44034, 130)\n",
      "Shape after selection:  (44034, 20)\n",
      "Model expects:          20 features\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# Load the GSE raster stack\n",
    "with rasterio.open(gse_stack_path) as src:\n",
    "    gse_stack = src.read()  # shape: (bands, rows, cols)\n",
    "    profile = src.profile\n",
    "    print(\"Bands in full GSE stack:\", src.count)\n",
    "\n",
    "n_bands, n_rows, n_cols = gse_stack.shape\n",
    "\n",
    "# Reshape the raster to (pixels, bands)\n",
    "gse_2d = gse_stack.reshape(n_bands, -1).T  # shape: (pixels, bands)\n",
    "\n",
    "# ---------------------------------------\n",
    "# ✅ Select only the bands used during training\n",
    "# ---------------------------------------\n",
    "\n",
    "# Suppose your training used columns like 'band_1'...'band_20'\n",
    "# Extract the numeric band indices from column names\n",
    "train_band_indices = [int(col.split('_')[-1]) - 1 for col in X_train.columns]  \n",
    "# (subtract 1 because raster bands are 0-indexed in numpy)\n",
    "\n",
    "# Subset gse_2d to only those bands (and preserve order)\n",
    "gse_2d_selected = gse_2d[:, train_band_indices]\n",
    "\n",
    "print(f\"Shape before selection: {gse_2d.shape}\")\n",
    "print(f\"Shape after selection:  {gse_2d_selected.shape}\")\n",
    "print(f\"Model expects:          {best_rf_model.n_features_in_} features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75a4e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predicted dNBR (10m) saved at: /Users/ceedindia/Desktop/Fire/Data/Trial/predicted_dNBR_10m__.tif\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Predict in batches\n",
    "# ---------------------------------------\n",
    "batch_size = 500000\n",
    "preds = []\n",
    "\n",
    "for i in range(0, gse_2d_selected.shape[0], batch_size):\n",
    "    batch = gse_2d_selected[i:i+batch_size]\n",
    "    preds_batch = best_rf_model.predict(batch)\n",
    "    preds.extend(preds_batch)\n",
    "\n",
    "preds = np.array(preds)\n",
    "\n",
    "# Reshape predictions back to raster grid\n",
    "predicted_dnbr_10m = preds.reshape(n_rows, n_cols)\n",
    "\n",
    "# Save predicted map\n",
    "profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "output_path = '/Users/ceedindia/Desktop/Fire/Data/Trial/predicted_dNBR_10m__.tif'\n",
    "\n",
    "with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "    dst.write(predicted_dnbr_10m.astype(np.float32), 1)\n",
    "\n",
    "print(f\"✅ Predicted dNBR (10m) saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f14520",
   "metadata": {},
   "source": [
    "# ============================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f108713",
   "metadata": {},
   "source": [
    "Step 8: XGBoost with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d64910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost hyperparameter tuning (10-fold CV)...\n",
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  14.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  14.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  18.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  18.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  19.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  18.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  18.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  18.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  19.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  17.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  19.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  22.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  22.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  22.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  23.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  20.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  21.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  23.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  23.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   7.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.6; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   7.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   6.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   6.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=1500, subsample=1.0; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=   8.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=   9.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.6; total time=  10.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=  10.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8; total time=   9.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0; total time=   9.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   8.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=500, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  19.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  20.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.6; total time=  20.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  22.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  20.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  22.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=0.8; total time=  22.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  21.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=1500, subsample=1.0; total time=  21.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  26.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  27.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.6; total time=  26.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  26.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  23.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  26.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  24.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=0.8; total time=  25.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=2000, subsample=1.0; total time=  24.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.6; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=1500, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.6; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.6; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   6.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.6; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=1500, subsample=0.8; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   7.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.6; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=2000, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=1500, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.6; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=1500, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=1500, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=15.0min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=15.0min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=1.0; total time=15.0min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=15.0min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=15.0min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=15.1min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.6; total time=15.1min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.6; total time=15.0min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=15.1min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=2000, subsample=0.8; total time=15.1min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=1500, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=2000, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=1500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=2000, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=1500, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=2000, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=500, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=1500, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=2000, subsample=0.8; total time=   1.9s\n",
      "\n",
      "Best XGBoost parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 2000, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost hyperparameter grid\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [500, 1500, 2000],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"\\nXGBoost hyperparameter tuning (10-fold CV)...\")\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest XGBoost parameters: {xgb_grid_search.best_params_}\")\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5abd09c",
   "metadata": {},
   "source": [
    "Step 9: Evaluate XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "836891de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 5-fold CV RMSE: 0.0609\n",
      "\n",
      "XGBoost Test Performance:\n",
      "RMSE: 0.0554\n",
      "MAE: 0.0365\n",
      "MAPE: 37.60%\n",
      "R²: 0.9018\n",
      "\n",
      "Accuracy Matrix:\n",
      "                    ±5%       ±10%       ±15%       ±20%\n",
      "Accuracy (%)  15.213675  31.495726  45.897436  56.752137\n"
     ]
    }
   ],
   "source": [
    "# # 5-fold CV\n",
    "# xgb_cv_scores_5fold = cross_val_score(\n",
    "#     best_xgb_model, X_train, y_train, \n",
    "#     cv=10, \n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# print(f\"XGBoost 5-fold CV RMSE: {np.sqrt(-xgb_cv_scores_5fold.mean()):.4f}\")\n",
    "\n",
    "# # Test set evaluation\n",
    "# y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "# xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "# xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# print(f\"\\nXGBoost Test Performance:\")\n",
    "# print(f\"RMSE: {xgb_rmse:.4f}\")\n",
    "# print(f\"R²: {xgb_r2:.4f}\")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 10-fold Cross-Validation\n",
    "# -----------------------------\n",
    "xgb_cv_scores_5fold = cross_val_score(\n",
    "    best_xgb_model, X_train, y_train, \n",
    "    cv=10, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"XGBoost 5-fold CV RMSE: {np.sqrt(-xgb_cv_scores_5fold.mean()):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Test Set Evaluation\n",
    "# -----------------------------\n",
    "y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "xgb_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "xgb_mape = np.mean(np.abs((y_test - y_pred_xgb) / y_test)) * 100\n",
    "\n",
    "xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# -----------------------------\n",
    "# Accuracy Matrix (within tolerance)\n",
    "# -----------------------------\n",
    "tolerances = [0.05, 0.10, 0.15, 0.20]  # ±5%, ±10%, ±15%, ±20%\n",
    "accuracy_data = {}\n",
    "\n",
    "for tol in tolerances:\n",
    "    within_tol = np.abs((y_pred_xgb - y_test) / y_test) <= tol\n",
    "    accuracy = np.mean(within_tol) * 100\n",
    "    accuracy_data[f'±{int(tol*100)}%'] = [accuracy]\n",
    "\n",
    "accuracy_matrix = pd.DataFrame(accuracy_data, index=['Accuracy (%)'])\n",
    "\n",
    "# -----------------------------\n",
    "# Print Results\n",
    "# -----------------------------\n",
    "print(f\"\\nXGBoost Test Performance:\")\n",
    "print(f\"RMSE: {xgb_rmse:.4f}\")\n",
    "print(f\"MAE: {xgb_mae:.4f}\")\n",
    "print(f\"MAPE: {xgb_mape:.2f}%\")\n",
    "print(f\"R²: {xgb_r2:.4f}\")\n",
    "\n",
    "print(\"\\nAccuracy Matrix:\")\n",
    "print(accuracy_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645de17",
   "metadata": {},
   "source": [
    "Step 10: Convert 10m Prediction Bands to DataFrame (for Prediction)\n",
    "Now, load the original 10m prediction bands to predict dNBR at 10m resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "898fc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def raster_to_dataframe_10m(prediction_10m_path):\n",
    "#     \"\"\"\n",
    "#     Convert 10m prediction bands to dataframe for prediction\n",
    "#     \"\"\"\n",
    "#     with rasterio.open(prediction_10m_path) as pred_src:\n",
    "#         pred_data = pred_src.read()\n",
    "#         n_bands = pred_src.count\n",
    "#         height = pred_src.height\n",
    "#         width = pred_src.width\n",
    "#         transform = pred_src.transform\n",
    "        \n",
    "#         # Get coordinates\n",
    "#         rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
    "#         xs, ys = rasterio.transform.xy(transform, rows.flatten(), cols.flatten())\n",
    "        \n",
    "#         # Flatten\n",
    "#         pred_data_flat = pred_data.reshape(n_bands, -1).T\n",
    "        \n",
    "#         # Create dataframe\n",
    "#         df = pd.DataFrame(pred_data_flat, \n",
    "#                          columns=[f'band_{i+1}' for i in range(n_bands)])\n",
    "#         df['longitude'] = xs\n",
    "#         df['latitude'] = ys\n",
    "#         df['row'] = rows.flatten()\n",
    "#         df['col'] = cols.flatten()\n",
    "    \n",
    "#     # Remove nodata\n",
    "#     df = df.replace([np.inf, -np.inf], np.nan)\n",
    "#     df = df.dropna()\n",
    "    \n",
    "#     return df, height, width, transform\n",
    "\n",
    "# # Load 10m prediction data\n",
    "# df_pred_10m, height_10m, width_10m, transform_10m = raster_to_dataframe_10m(\n",
    "#     '/Users/ceedindia/Desktop/Fire/Data/Trial/GSE_Dirang_Prediction_Band_after64.tif'\n",
    "# )\n",
    "\n",
    "# print(f\"10m prediction data shape: {df_pred_10m.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156f10a",
   "metadata": {},
   "source": [
    "Step 11: Predict dNBR at 10m Resolution\n",
    "Use the trained model (trained on 20m data) to predict dNBR at 10m resolution:​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66104bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract features for prediction\n",
    "# X_pred_10m = df_pred_10m[feature_cols]\n",
    "\n",
    "# # Choose best model\n",
    "# if rf_r2 > xgb_r2:\n",
    "#     print(\"\\nUsing Random Forest for 10m prediction\")\n",
    "#     final_model = best_rf_model\n",
    "# else:\n",
    "#     print(\"\\nUsing XGBoost for 10m prediction\")\n",
    "#     final_model = best_xgb_model\n",
    "\n",
    "# # Predict dNBR at 10m\n",
    "# predicted_dnbr_10m = final_model.predict(X_pred_10m)\n",
    "\n",
    "# print(f\"Predicted dNBR at 10m: {predicted_dnbr_10m.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa06e1",
   "metadata": {},
   "source": [
    "Step 12: Convert Predictions Back to 10m Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b90b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predictions_to_raster_10m(predictions, df_coords, height, width, transform, output_path, reference_path):\n",
    "#     \"\"\"\n",
    "#     Convert 10m predictions back to georeferenced raster\n",
    "#     \"\"\"\n",
    "#     with rasterio.open(reference_path) as src:\n",
    "#         profile = src.profile.copy()\n",
    "    \n",
    "#     # Create empty array\n",
    "#     pred_array = np.full((height, width), np.nan, dtype=np.float32)\n",
    "    \n",
    "#     # Fill with predictions\n",
    "#     for idx, (row, col, pred) in enumerate(zip(df_coords['row'], \n",
    "#                                                  df_coords['col'], \n",
    "#                                                  predictions)):\n",
    "#         pred_array[int(row), int(col)] = pred\n",
    "    \n",
    "#     # Update profile\n",
    "#     profile.update({\n",
    "#         'count': 1,\n",
    "#         'dtype': 'float32',\n",
    "#         'height': height,\n",
    "#         'width': width,\n",
    "#         'transform': transform,\n",
    "#         'nodata': np.nan\n",
    "#     })\n",
    "    \n",
    "#     # Write raster\n",
    "#     with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "#         dst.write(pred_array, 1)\n",
    "    \n",
    "#     print(f\"Predicted dNBR raster saved: {output_path}\")\n",
    "\n",
    "# # Save predicted dNBR at 10m\n",
    "# predictions_to_raster_10m(\n",
    "#     predicted_dnbr_10m,\n",
    "#     df_pred_10m,\n",
    "#     height_10m,\n",
    "#     width_10m,\n",
    "#     transform_10m,\n",
    "#     'predicted_dnbr_10m.tif',\n",
    "#     'prediction_bands_10m.tif'\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
